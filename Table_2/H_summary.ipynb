{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bb0da68-16ec-4cb5-b313-e724d38f2281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded parameters for 5 frequencies from parameter_table.csv\n",
      "================================================================================\n",
      "MIN-ENTROPY ANALYSIS WITH DYNAMIC PARAMETERS\n",
      "================================================================================\n",
      "Analysis started at: 2026-01-15 13:51:53.491581\n",
      "Analyzing n_history values: [1, 3, 5]\n",
      "b is automatically determined from r_u sign\n",
      "================================================================================\n",
      "\n",
      "========================================\n",
      "ANALYZING WITH n = 1\n",
      "========================================\n",
      "\n",
      "Analyzing file: 1.3V_1G.bin\n",
      "90B test result: 0.613673\n",
      "Extracted frequency: 1GHz.bin\n",
      "WARNING: No parameters found for frequency 1GHz.bin\n",
      "\n",
      "Analyzing file: 1.3V_2G.bin\n",
      "90B test result: 0.567689\n",
      "Extracted frequency: 2GHz.bin\n",
      "WARNING: No parameters found for frequency 2GHz.bin\n",
      "\n",
      "Analyzing file: 1.3V_3G.bin\n",
      "90B test result: 0.519764\n",
      "Extracted frequency: 3GHz.bin\n",
      "WARNING: No parameters found for frequency 3GHz.bin\n",
      "\n",
      "Analyzing file: 1.3V_4G.bin\n",
      "90B test result: 0.513656\n",
      "Extracted frequency: 4GHz.bin\n",
      "WARNING: No parameters found for frequency 4GHz.bin\n",
      "\n",
      "Analyzing file: 1.3V_5G.bin\n",
      "90B test result: 0.328293\n",
      "Extracted frequency: 5GHz.bin\n",
      "WARNING: No parameters found for frequency 5GHz.bin\n",
      "\n",
      "========================================\n",
      "RESULTS SUMMARY FOR n = 1\n",
      "========================================\n",
      "Frequency    90B Test     Linear       Monte Carlo  Diff (Lin)   Diff (MC)   \n",
      "--------------------------------------------------------------------------------\n",
      "TeX table saved to entropy_results_table_n1.tex\n",
      "\n",
      "========================================\n",
      "ANALYZING WITH n = 3\n",
      "========================================\n",
      "\n",
      "Analyzing file: 1.3V_1G.bin\n",
      "90B test result: 0.613673\n",
      "Extracted frequency: 1GHz.bin\n",
      "WARNING: No parameters found for frequency 1GHz.bin\n",
      "\n",
      "Analyzing file: 1.3V_2G.bin\n",
      "90B test result: 0.567689\n",
      "Extracted frequency: 2GHz.bin\n",
      "WARNING: No parameters found for frequency 2GHz.bin\n",
      "\n",
      "Analyzing file: 1.3V_3G.bin\n",
      "90B test result: 0.519764\n",
      "Extracted frequency: 3GHz.bin\n",
      "WARNING: No parameters found for frequency 3GHz.bin\n",
      "\n",
      "Analyzing file: 1.3V_4G.bin\n",
      "90B test result: 0.513656\n",
      "Extracted frequency: 4GHz.bin\n",
      "WARNING: No parameters found for frequency 4GHz.bin\n",
      "\n",
      "Analyzing file: 1.3V_5G.bin\n",
      "90B test result: 0.328293\n",
      "Extracted frequency: 5GHz.bin\n",
      "WARNING: No parameters found for frequency 5GHz.bin\n",
      "\n",
      "========================================\n",
      "RESULTS SUMMARY FOR n = 3\n",
      "========================================\n",
      "Frequency    90B Test     Linear       Monte Carlo  Diff (Lin)   Diff (MC)   \n",
      "--------------------------------------------------------------------------------\n",
      "TeX table saved to entropy_results_table_n3.tex\n",
      "\n",
      "========================================\n",
      "ANALYZING WITH n = 5\n",
      "========================================\n",
      "\n",
      "Analyzing file: 1.3V_1G.bin\n",
      "90B test result: 0.613673\n",
      "Extracted frequency: 1GHz.bin\n",
      "WARNING: No parameters found for frequency 1GHz.bin\n",
      "\n",
      "Analyzing file: 1.3V_2G.bin\n",
      "90B test result: 0.567689\n",
      "Extracted frequency: 2GHz.bin\n",
      "WARNING: No parameters found for frequency 2GHz.bin\n",
      "\n",
      "Analyzing file: 1.3V_3G.bin\n",
      "90B test result: 0.519764\n",
      "Extracted frequency: 3GHz.bin\n",
      "WARNING: No parameters found for frequency 3GHz.bin\n",
      "\n",
      "Analyzing file: 1.3V_4G.bin\n",
      "90B test result: 0.513656\n",
      "Extracted frequency: 4GHz.bin\n",
      "WARNING: No parameters found for frequency 4GHz.bin\n",
      "\n",
      "Analyzing file: 1.3V_5G.bin\n",
      "90B test result: 0.328293\n",
      "Extracted frequency: 5GHz.bin\n",
      "WARNING: No parameters found for frequency 5GHz.bin\n",
      "\n",
      "========================================\n",
      "RESULTS SUMMARY FOR n = 5\n",
      "========================================\n",
      "Frequency    90B Test     Linear       Monte Carlo  Diff (Lin)   Diff (MC)   \n",
      "--------------------------------------------------------------------------------\n",
      "TeX table saved to entropy_results_table_n5.tex\n",
      "\n",
      "================================================================================\n",
      "GENERATING TABLES WITH MERGED HEADER FORMAT\n",
      "================================================================================\n",
      "Merged format CSV table saved to entropy_results_merged_format.csv\n",
      "openpyxl not installed. Cannot generate Excel file.\n",
      "Please install openpyxl: pip install openpyxl\n",
      "Merged format TeX table saved to entropy_results_merged_format.tex\n",
      "\n",
      "================================================================================\n",
      "CREATING VISUALIZATIONS FOR n=1\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No results to save\n",
      "No results to save\n",
      "No results to save\n",
      "No results to save\n",
      "No results to save\n",
      "No results to save\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No valid results for visualization\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE\n",
      "================================================================================\n",
      "Generated files:\n",
      "  For n=1:\n",
      "    1. entropy_results_n1_summary.csv\n",
      "    2. entropy_results_n1_detailed.csv\n",
      "    3. entropy_results_table_n1.tex\n",
      "  For n=3:\n",
      "    1. entropy_results_n3_summary.csv\n",
      "    2. entropy_results_n3_detailed.csv\n",
      "    3. entropy_results_table_n3.tex\n",
      "  For n=5:\n",
      "    1. entropy_results_n5_summary.csv\n",
      "    2. entropy_results_n5_detailed.csv\n",
      "    3. entropy_results_table_n5.tex\n",
      "\n",
      "  Multi-n tables with merged header format:\n",
      "    1. entropy_results_merged_format.csv\n",
      "    2. entropy_results_merged_format.xlsx (Excel format with merged cells)\n",
      "    3. entropy_results_merged_format.tex (TeX format with merged cells)\n",
      "\n",
      "  Visualizations (for n=1):\n",
      "    1. entropy_analysis_visualizations.png (if matplotlib available)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Min-entropy analysis with dynamic parameters - MULTIPLE n_history VERSION\n",
    "Generate tables, CSV files, TeX output, and visualizations\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from typing import Tuple, List, Dict\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import csv\n",
    "\n",
    "# ---------- Standard normal distribution functions ----------\n",
    "SQRT2 = math.sqrt(2.0)\n",
    "SQRT2PI = math.sqrt(2.0 * math.pi)\n",
    "\n",
    "def phi(x: float) -> float:\n",
    "    \"\"\"Standard normal PDF\"\"\"\n",
    "    return math.exp(-0.5 * x * x) / SQRT2PI\n",
    "\n",
    "def Phi(x: float) -> float:\n",
    "    \"\"\"Standard normal CDF\"\"\"\n",
    "    return 0.5 * (1.0 + math.erf(x / SQRT2))\n",
    "\n",
    "# ---------- Correlation model ----------\n",
    "def rho_lags(n: int, alpha: float, beta: float) -> np.ndarray:\n",
    "    \"\"\"Return correlation function rho[1..n]\"\"\"\n",
    "    k = np.arange(1, n + 1, dtype=float)\n",
    "    return alpha * np.power(k, -beta)\n",
    "\n",
    "# ---------- Min-entropy calculation ----------\n",
    "def hmin_from_p(p: float) -> float:\n",
    "    \"\"\"Compute min-entropy from conditional probability p\"\"\"\n",
    "    p = float(np.clip(p, 1e-12, 1.0 - 1e-12))\n",
    "    q = max(p, 1.0 - p)\n",
    "    return -math.log2(q)\n",
    "\n",
    "# ---------- First-order approximation of p ----------\n",
    "def p_cond_first_order_all_same(n: int, r: float, alpha: float, beta: float, b: int = -1) -> float:\n",
    "    \"\"\"\n",
    "    First-order approximation of conditional probability p(b_n=b | b_0=...=b_{n-1}=b)\n",
    "    \"\"\"\n",
    "    rho = rho_lags(n, alpha=alpha, beta=beta)\n",
    "    s1 = float(np.sum(rho))\n",
    "    \n",
    "    if abs(r) < 1e-14:\n",
    "        p = 0.5 + (1.0 / math.pi) * s1\n",
    "    else:\n",
    "        p0 = Phi(b * r)\n",
    "        p0 = min(max(p0, 1e-15), 1.0 - 1e-15)\n",
    "        p = p0 + (phi(r) ** 2 / p0) * s1\n",
    "    \n",
    "    return float(np.clip(p, 1e-12, 1.0 - 1e-12))\n",
    "\n",
    "# ---------- Toeplitz correlation matrix ----------\n",
    "def toeplitz_corr_matrix(n: int, alpha: float, beta: float) -> np.ndarray:\n",
    "    \"\"\"Build (n+1)x(n+1) Toeplitz correlation matrix\"\"\"\n",
    "    dim = n + 1\n",
    "    rho = rho_lags(n, alpha=alpha, beta=beta)\n",
    "    first_row = np.concatenate(([1.0], rho))\n",
    "    R = np.empty((dim, dim), dtype=float)\n",
    "    for i in range(dim):\n",
    "        for j in range(dim):\n",
    "            R[i, j] = first_row[abs(i - j)]\n",
    "    return R\n",
    "\n",
    "def cholesky_with_jitter(R: np.ndarray, jitter0: float = 1e-12, max_tries: int = 12) -> np.ndarray:\n",
    "    \"\"\"Cholesky decomposition with jitter\"\"\"\n",
    "    jitter = jitter0\n",
    "    I = np.eye(R.shape[0], dtype=float)\n",
    "    for _ in range(max_tries):\n",
    "        try:\n",
    "            return np.linalg.cholesky(R + jitter * I)\n",
    "        except np.linalg.LinAlgError:\n",
    "            jitter *= 10.0\n",
    "    raise np.linalg.LinAlgError(\"Cholesky decomposition failed\")\n",
    "\n",
    "# ---------- Monte Carlo estimation of p ----------\n",
    "def p_cond_monte_carlo_all_same(\n",
    "    n: int,\n",
    "    r: float,\n",
    "    alpha: float,\n",
    "    beta: float,\n",
    "    b: int = -1,\n",
    "    num_samples: int = 50000,\n",
    "    seed: int = 0,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Monte Carlo estimation of conditional probability\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    dim = n + 1\n",
    "    \n",
    "    R = toeplitz_corr_matrix(n, alpha=alpha, beta=beta)\n",
    "    L = cholesky_with_jitter(R)\n",
    "    \n",
    "    eps = rng.standard_normal(size=(dim, num_samples))\n",
    "    Z = (L @ eps).T\n",
    "    V = Z + r\n",
    "    \n",
    "    B = np.where(V >= 0.0, 1, -1)\n",
    "    past_ok = np.all(B[:, :n] == b, axis=1)\n",
    "    denom = int(np.sum(past_ok))\n",
    "    \n",
    "    if denom == 0:\n",
    "        return 0.5  # Return default value\n",
    "    \n",
    "    num = int(np.sum(B[past_ok, n] == b))\n",
    "    p = num / denom\n",
    "    return float(np.clip(p, 1e-12, 1.0 - 1e-12))\n",
    "\n",
    "# ---------- Read data from bin file ----------\n",
    "def read_bin_file(filename: str, max_bits: int = 200000) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Read bin file, each byte stores one bit\n",
    "    Return array in ±1 format\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if file exists\n",
    "        if not os.path.exists(filename):\n",
    "            print(f\"  ERROR: File {filename} does not exist!\", file=sys.stderr)\n",
    "            return np.array([])\n",
    "            \n",
    "        with open(filename, 'rb') as f:\n",
    "            data = f.read()\n",
    "        \n",
    "        if len(data) == 0:\n",
    "            print(f\"  ERROR: File {filename} is empty!\", file=sys.stderr)\n",
    "            return np.array([])\n",
    "        \n",
    "        # Limit data for faster computation\n",
    "        if len(data) > max_bits:\n",
    "            data = data[:max_bits]\n",
    "        \n",
    "        # Convert bytes to ±1\n",
    "        bits = np.frombuffer(data, dtype=np.uint8)\n",
    "        \n",
    "        # Check data range\n",
    "        unique_vals = np.unique(bits)\n",
    "        \n",
    "        # Convert based on actual values\n",
    "        if len(unique_vals) == 2 and 0 in unique_vals and 1 in unique_vals:\n",
    "            # Standard case: 0 and 1\n",
    "            bits_converted = np.where(bits == 0, -1, 1)\n",
    "        elif len(unique_vals) == 2 and 0 in unique_vals and 255 in unique_vals:\n",
    "            # Possibly 0 and 255\n",
    "            bits_converted = np.where(bits == 0, -1, 1)\n",
    "        else:\n",
    "            # Other cases, use LSB\n",
    "            bits_converted = np.where(bits & 1 == 0, -1, 1)\n",
    "        \n",
    "        return bits_converted\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR reading file {filename}: {e}\", file=sys.stderr)\n",
    "        return np.array([])\n",
    "\n",
    "# ---------- Load parameters from CSV ----------\n",
    "def load_parameters_from_csv(csv_file: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Load parameters from CSV file\n",
    "    Expected format: Frequency,Folder,N,p_hat,r_u,r_f,beta,gamma,A,K_ru,R2\n",
    "    \"\"\"\n",
    "    parameters = {}\n",
    "    \n",
    "    try:\n",
    "        with open(csv_file, 'r', encoding='utf-8-sig') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                freq = row['Frequency']\n",
    "                # Store all parameters for this frequency\n",
    "                parameters[freq] = {\n",
    "                    'Frequency': freq,\n",
    "                    'Folder': row['Folder'],\n",
    "                    'N': int(row['N']),\n",
    "                    'p_hat': float(row['p_hat']),\n",
    "                    'r_u': float(row['r_u']),\n",
    "                    'r_f': float(row['r_f']),\n",
    "                    'beta': float(row['beta']),\n",
    "                    'gamma': float(row['gamma']),\n",
    "                    'A': float(row['A']),\n",
    "                    'K_ru': float(row['K_ru']),\n",
    "                    'R2': float(row['R2'])\n",
    "                }\n",
    "        \n",
    "        print(f\"Loaded parameters for {len(parameters)} frequencies from {csv_file}\")\n",
    "        return parameters\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading parameters from CSV: {e}\", file=sys.stderr)\n",
    "        return {}\n",
    "\n",
    "# ---------- Determine b based on r_u ----------\n",
    "def determine_b_from_r_u(r_u: float) -> int:\n",
    "    \"\"\"\n",
    "    Determine b value based on r_u:\n",
    "    - If r_u is negative, b = -1\n",
    "    - If r_u is positive, b = 1\n",
    "    - If r_u is zero, b = -1 (default)\n",
    "    \"\"\"\n",
    "    if r_u < 0:\n",
    "        return -1\n",
    "    elif r_u > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1  # Default when r_u is exactly 0\n",
    "\n",
    "# ---------- Analyze bin file with parameters ----------\n",
    "def analyze_bin_file_with_params(filename: str, n_history: int, \n",
    "                                alpha: float, beta: float, \n",
    "                                r_u: float, mc_samples: int = 50000) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyze bin file with specific parameters\n",
    "    b is determined automatically based on r_u\n",
    "    r value is r_u from the CSV file\n",
    "    \"\"\"\n",
    "    # Read data\n",
    "    bits = read_bin_file(filename, max_bits=200000)\n",
    "    if len(bits) == 0:\n",
    "        return {\n",
    "            'filename': filename,\n",
    "            'hmin_linear': 0.0,\n",
    "            'hmin_mc': 0.0,\n",
    "            'p_linear': 0.5,\n",
    "            'p_mc': 0.5,\n",
    "            'error': 'Failed to read file'\n",
    "        }\n",
    "    \n",
    "    # Use r_u as the r parameter\n",
    "    r = r_u\n",
    "    \n",
    "    # Determine b based on r_u\n",
    "    b = determine_b_from_r_u(r_u)\n",
    "    \n",
    "    # Method 1: First-order approximation\n",
    "    p_linear = p_cond_first_order_all_same(n_history, r, alpha, beta, b)\n",
    "    hmin_linear = hmin_from_p(p_linear)\n",
    "    \n",
    "    # Method 2: Monte Carlo\n",
    "    p_mc = p_cond_monte_carlo_all_same(\n",
    "        n_history, r, alpha, beta, b,\n",
    "        num_samples=mc_samples, seed=42\n",
    "    )\n",
    "    hmin_mc = hmin_from_p(p_mc)\n",
    "    \n",
    "    # Calculate bias from data\n",
    "    p1_actual = np.mean(bits == 1)\n",
    "    bias = abs(p1_actual - 0.5)\n",
    "    \n",
    "    return {\n",
    "        'filename': filename,\n",
    "        'hmin_linear': hmin_linear,\n",
    "        'hmin_mc': hmin_mc,\n",
    "        'p_linear': p_linear,\n",
    "        'p_mc': p_mc,\n",
    "        'r': r,\n",
    "        'r_u': r_u,\n",
    "        'b': b,\n",
    "        'b_determination': 'from_r_u',\n",
    "        'p1_actual': p1_actual,\n",
    "        'bias': bias,\n",
    "        'alpha': alpha,\n",
    "        'beta': beta,\n",
    "        'n_history': n_history,\n",
    "        'bits_analyzed': len(bits),\n",
    "        'error': None\n",
    "    }\n",
    "\n",
    "# ---------- Save results to CSV ----------\n",
    "def save_results_to_csv(results: List[Dict], filename: str, n_history: int = None, include_params: bool = False):\n",
    "    \"\"\"Save analysis results to CSV file\"\"\"\n",
    "    if not results:\n",
    "        print(\"No results to save\", file=sys.stderr)\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Determine field names\n",
    "        fieldnames = ['Frequency', '90B_Result', 'Linear_Estimate', 'MonteCarlo_Estimate']\n",
    "        if include_params:\n",
    "            fieldnames.extend(['p_hat', 'r_u', 'alpha', 'beta', 'b', 'n_history'])\n",
    "        \n",
    "        with open(filename, 'w', newline='') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            \n",
    "            for result in results:\n",
    "                # Extract frequency from filename\n",
    "                freq = result['filename'].split('_')[1].replace('G', 'GHz')\n",
    "                \n",
    "                row_data = {\n",
    "                    'Frequency': freq,\n",
    "                    '90B_Result': result['hmin_90b'],\n",
    "                    'Linear_Estimate': result['hmin_linear'],\n",
    "                    'MonteCarlo_Estimate': result['hmin_mc']\n",
    "                }\n",
    "                \n",
    "                if include_params:\n",
    "                    row_data.update({\n",
    "                        'p_hat': result.get('p_hat', 0.5),\n",
    "                        'r_u': result.get('r_u', 0.0),\n",
    "                        'alpha': result.get('alpha', 0.0),\n",
    "                        'beta': result.get('beta', 0.0),\n",
    "                        'b': result.get('b', 0),\n",
    "                        'n_history': n_history if n_history is not None else result.get('n_history', 8)\n",
    "                    })\n",
    "                \n",
    "                writer.writerow(row_data)\n",
    "        \n",
    "        print(f\"Results saved to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving results to CSV: {e}\", file=sys.stderr)\n",
    "\n",
    "# ---------- Generate TeX table for single n_history ----------\n",
    "def generate_tex_table(results: List[Dict], filename: str, n_history: int = None):\n",
    "    \"\"\"Generate LaTeX table from results for a single n_history\"\"\"\n",
    "    try:\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(\"% LaTeX table generated by min-entropy analysis\\n\")\n",
    "            f.write(\"% Date: \" + datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \"\\n\")\n",
    "            f.write(\"\\\\begin{table}[htbp]\\n\")\n",
    "            f.write(\"\\\\centering\\n\")\n",
    "            \n",
    "            # Add n_history to caption if provided\n",
    "            if n_history is not None:\n",
    "                f.write(f\"\\\\caption{{Comparison of Min-Entropy Estimation Methods (n={n_history})}}\\n\")\n",
    "            else:\n",
    "                f.write(\"\\\\caption{Comparison of Min-Entropy Estimation Methods}\\n\")\n",
    "                \n",
    "            f.write(\"\\\\label{tab:entropy_comparison}\\n\")\n",
    "            f.write(\"\\\\begin{tabular}{cccc}\\n\")\n",
    "            f.write(\"\\\\hline\\n\")\n",
    "            f.write(\"Frequency & 90B Test & Linear Estimate & Monte Carlo Estimate \\\\\\\\\\n\")\n",
    "            f.write(\"\\\\hline\\n\")\n",
    "            \n",
    "            for result in results:\n",
    "                freq = result['filename'].split('_')[1].replace('G', 'GHz')\n",
    "                f.write(f\"{freq} & {result['hmin_90b']:.6f} & {result['hmin_linear']:.6f} & {result['hmin_mc']:.6f} \\\\\\\\\\n\")\n",
    "            \n",
    "            f.write(\"\\\\hline\\n\")\n",
    "            f.write(\"\\\\end{tabular}\\n\")\n",
    "            f.write(\"\\\\end{table}\\n\")\n",
    "        \n",
    "        print(f\"TeX table saved to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating TeX table: {e}\", file=sys.stderr)\n",
    "\n",
    "# ---------- Generate TeX table with merged cells ----------\n",
    "def generate_merged_format_tex_table(multi_results: Dict[int, List[Dict]], filename: str):\n",
    "    \"\"\"Generate LaTeX table with merged Linear Estimate and Monte Carlo Estimate headers\"\"\"\n",
    "    try:\n",
    "        n_vals = sorted(multi_results.keys())  # Should be [1, 3, 5]\n",
    "        \n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(\"% LaTeX table generated by min-entropy analysis\\n\")\n",
    "            f.write(\"% Date: \" + datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") + \"\\n\")\n",
    "            f.write(\"\\\\begin{table}[htbp]\\n\")\n",
    "            f.write(\"\\\\centering\\n\")\n",
    "            f.write(\"\\\\caption{Min-Entropy Estimation Results for Different n Values}\\n\")\n",
    "            f.write(\"\\\\label{tab:entropy_results_merged}\\n\")\n",
    "            \n",
    "            # Create table with correct column format\n",
    "            # Format: l (Frequency), c (90B Test), then 3 c for Linear Estimate, then 3 c for Monte Carlo Estimate\n",
    "            col_format = \"l\" + \"c\" * (1 + 3 + 3)  # l for Frequency, then 7 c columns\n",
    "            \n",
    "            f.write(f\"\\\\begin{{tabular}}{{{col_format}}}\\n\")\n",
    "            f.write(\"\\\\hline\\n\")\n",
    "            \n",
    "            # First header row with merged cells\n",
    "            # Frequency and 90B Test span 2 rows, Linear Estimate spans 3 columns, Monte Carlo Estimate spans 3 columns\n",
    "            f.write(\"\\\\multirow{2}{*}{Frequency} & \\\\multirow{2}{*}{90B Test} & \\\\multicolumn{3}{c}{Linear Estimate} & \\\\multicolumn{3}{c}{Monte Carlo Estimate} \\\\\\\\\\n\")\n",
    "            \n",
    "            # Second header row - n values under Linear and Monte Carlo\n",
    "            f.write(\"\\\\cline{3-8}\\n\")\n",
    "            f.write(\" & & n=1 & n=3 & n=5 & n=1 & n=3 & n=5 \\\\\\\\\\n\")\n",
    "            \n",
    "            f.write(\"\\\\hline\\n\")\n",
    "            \n",
    "            # Get frequencies from the first n value's results\n",
    "            first_n = n_vals[0]\n",
    "            first_results = multi_results[first_n]\n",
    "            \n",
    "            # For each frequency, create a row\n",
    "            for result in first_results:\n",
    "                freq = result['filename'].split('_')[1].replace('G', 'GHz')\n",
    "                row = f\"{freq} & {result['hmin_90b']:.6f}\"\n",
    "                \n",
    "                # Add linear estimates for all n values\n",
    "                for n in n_vals:\n",
    "                    n_results = multi_results[n]\n",
    "                    n_result = next((r for r in n_results if r['filename'] == result['filename']), None)\n",
    "                    \n",
    "                    if n_result:\n",
    "                        row += f\" & {n_result['hmin_linear']:.6f}\"\n",
    "                    else:\n",
    "                        row += \" & -\"\n",
    "                \n",
    "                # Add Monte Carlo estimates for all n values\n",
    "                for n in n_vals:\n",
    "                    n_results = multi_results[n]\n",
    "                    n_result = next((r for r in n_results if r['filename'] == result['filename']), None)\n",
    "                    \n",
    "                    if n_result:\n",
    "                        row += f\" & {n_result['hmin_mc']:.6f}\"\n",
    "                    else:\n",
    "                        row += \" & -\"\n",
    "                \n",
    "                row += \" \\\\\\\\\\n\"\n",
    "                f.write(row)\n",
    "            \n",
    "            f.write(\"\\\\hline\\n\")\n",
    "            f.write(\"\\\\end{tabular}\\n\")\n",
    "            f.write(\"\\\\end{table}\\n\")\n",
    "        \n",
    "        print(f\"Merged format TeX table saved to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating merged format TeX table: {e}\", file=sys.stderr)\n",
    "\n",
    "# ---------- Generate Excel table with merged cells ----------\n",
    "def generate_merged_format_excel_table(multi_results: Dict[int, List[Dict]], filename: str):\n",
    "    \"\"\"Generate Excel table with merged Linear Estimate and Monte Carlo Estimate headers\"\"\"\n",
    "    try:\n",
    "        # Try to import openpyxl for Excel generation\n",
    "        try:\n",
    "            from openpyxl import Workbook\n",
    "            from openpyxl.styles import Alignment, Border, Side, Font, PatternFill\n",
    "            from openpyxl.utils import get_column_letter\n",
    "        except ImportError:\n",
    "            print(\"openpyxl not installed. Cannot generate Excel file.\")\n",
    "            print(\"Please install openpyxl: pip install openpyxl\")\n",
    "            return\n",
    "        \n",
    "        n_vals = sorted(multi_results.keys())  # Should be [1, 3, 5]\n",
    "        \n",
    "        # Create a new workbook\n",
    "        wb = Workbook()\n",
    "        ws = wb.active\n",
    "        ws.title = \"Merged Format Results\"\n",
    "        \n",
    "        # Define styles\n",
    "        header_font = Font(bold=True, size=12)\n",
    "        header_fill = PatternFill(start_color=\"C0C0C0\", end_color=\"C0C0C0\", fill_type=\"solid\")\n",
    "        subheader_font = Font(bold=True, size=11)\n",
    "        subheader_fill = PatternFill(start_color=\"E0E0E0\", end_color=\"E0E0E0\", fill_type=\"solid\")\n",
    "        center_alignment = Alignment(horizontal=\"center\", vertical=\"center\", wrap_text=True)\n",
    "        border = Border(\n",
    "            left=Side(style=\"thin\"),\n",
    "            right=Side(style=\"thin\"),\n",
    "            top=Side(style=\"thin\"),\n",
    "            bottom=Side(style=\"thin\")\n",
    "        )\n",
    "        \n",
    "        # Write headers with merged cells\n",
    "        # First row: Frequency (merged A1:A2), 90B Test (merged B1:B2), Linear Estimate (merged C1:E1), Monte Carlo Estimate (merged F1:H1)\n",
    "        ws.merge_cells(start_row=1, start_column=1, end_row=2, end_column=1)  # Frequency\n",
    "        ws.cell(row=1, column=1, value=\"Frequency\").font = header_font\n",
    "        ws.cell(row=1, column=1).fill = header_fill\n",
    "        ws.cell(row=1, column=1).alignment = center_alignment\n",
    "        ws.cell(row=1, column=1).border = border\n",
    "        \n",
    "        ws.merge_cells(start_row=1, start_column=2, end_row=2, end_column=2)  # 90B Test\n",
    "        ws.cell(row=1, column=2, value=\"90B Test\").font = header_font\n",
    "        ws.cell(row=1, column=2).fill = header_fill\n",
    "        ws.cell(row=1, column=2).alignment = center_alignment\n",
    "        ws.cell(row=1, column=2).border = border\n",
    "        \n",
    "        # Linear Estimate header (spanning 3 columns in row 1)\n",
    "        ws.merge_cells(start_row=1, start_column=3, end_row=1, end_column=5)\n",
    "        ws.cell(row=1, column=3, value=\"Linear Estimate\").font = header_font\n",
    "        ws.cell(row=1, column=3).fill = header_fill\n",
    "        ws.cell(row=1, column=3).alignment = center_alignment\n",
    "        ws.cell(row=1, column=3).border = border\n",
    "        \n",
    "        # Monte Carlo Estimate header (spanning 3 columns in row 1)\n",
    "        ws.merge_cells(start_row=1, start_column=6, end_row=1, end_column=8)\n",
    "        ws.cell(row=1, column=6, value=\"Monte Carlo Estimate\").font = header_font\n",
    "        ws.cell(row=1, column=6).fill = header_fill\n",
    "        ws.cell(row=1, column=6).alignment = center_alignment\n",
    "        ws.cell(row=1, column=6).border = border\n",
    "        \n",
    "        # Second row: n values under Linear Estimate and Monte Carlo Estimate\n",
    "        # Linear Estimate n values (row 2, columns 3-5)\n",
    "        for i, n in enumerate(n_vals):\n",
    "            col = 3 + i\n",
    "            ws.cell(row=2, column=col, value=f\"n={n}\").font = subheader_font\n",
    "            ws.cell(row=2, column=col).fill = subheader_fill\n",
    "            ws.cell(row=2, column=col).alignment = center_alignment\n",
    "            ws.cell(row=2, column=col).border = border\n",
    "        \n",
    "        # Monte Carlo Estimate n values (row 2, columns 6-8)\n",
    "        for i, n in enumerate(n_vals):\n",
    "            col = 6 + i\n",
    "            ws.cell(row=2, column=col, value=f\"n={n}\").font = subheader_font\n",
    "            ws.cell(row=2, column=col).fill = subheader_fill\n",
    "            ws.cell(row=2, column=col).alignment = center_alignment\n",
    "            ws.cell(row=2, column=col).border = border\n",
    "        \n",
    "        # Get frequencies from the first n value's results\n",
    "        first_n = n_vals[0]\n",
    "        first_results = multi_results[first_n]\n",
    "        \n",
    "        # Write data rows starting from row 3\n",
    "        for row_idx, result in enumerate(first_results, start=3):\n",
    "            freq = result['filename'].split('_')[1].replace('G', 'GHz')\n",
    "            \n",
    "            # Frequency\n",
    "            ws.cell(row=row_idx, column=1, value=freq).alignment = center_alignment\n",
    "            ws.cell(row=row_idx, column=1).border = border\n",
    "            \n",
    "            # 90B Test result\n",
    "            ws.cell(row=row_idx, column=2, value=result['hmin_90b']).alignment = center_alignment\n",
    "            ws.cell(row=row_idx, column=2).border = border\n",
    "            \n",
    "            # Linear estimates for all n values\n",
    "            for i, n in enumerate(n_vals):\n",
    "                col = 3 + i\n",
    "                n_results = multi_results[n]\n",
    "                n_result = next((r for r in n_results if r['filename'] == result['filename']), None)\n",
    "                \n",
    "                if n_result:\n",
    "                    ws.cell(row=row_idx, column=col, value=n_result['hmin_linear']).alignment = center_alignment\n",
    "                else:\n",
    "                    ws.cell(row=row_idx, column=col, value=\"N/A\").alignment = center_alignment\n",
    "                \n",
    "                ws.cell(row=row_idx, column=col).border = border\n",
    "            \n",
    "            # Monte Carlo estimates for all n values\n",
    "            for i, n in enumerate(n_vals):\n",
    "                col = 6 + i\n",
    "                n_results = multi_results[n]\n",
    "                n_result = next((r for r in n_results if r['filename'] == result['filename']), None)\n",
    "                \n",
    "                if n_result:\n",
    "                    ws.cell(row=row_idx, column=col, value=n_result['hmin_mc']).alignment = center_alignment\n",
    "                else:\n",
    "                    ws.cell(row=row_idx, column=col, value=\"N/A\").alignment = center_alignment\n",
    "                \n",
    "                ws.cell(row=row_idx, column=col).border = border\n",
    "        \n",
    "        # Adjust column widths\n",
    "        column_widths = {\n",
    "            1: 12,  # Frequency\n",
    "            2: 12,  # 90B Test\n",
    "            3: 12,  # Linear n=1\n",
    "            4: 12,  # Linear n=3\n",
    "            5: 12,  # Linear n=5\n",
    "            6: 12,  # Monte Carlo n=1\n",
    "            7: 12,  # Monte Carlo n=3\n",
    "            8: 12   # Monte Carlo n=5\n",
    "        }\n",
    "        \n",
    "        for col, width in column_widths.items():\n",
    "            col_letter = get_column_letter(col)\n",
    "            ws.column_dimensions[col_letter].width = width\n",
    "        \n",
    "        # Save the workbook\n",
    "        wb.save(filename)\n",
    "        print(f\"Merged format Excel table saved to {filename}\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"openpyxl not available. Skipping Excel generation.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating merged format Excel table: {e}\", file=sys.stderr)\n",
    "\n",
    "# ---------- Generate CSV table with merged format ----------\n",
    "def generate_merged_format_csv_table(multi_results: Dict[int, List[Dict]], filename: str):\n",
    "    \"\"\"Generate CSV table with merged format header\"\"\"\n",
    "    try:\n",
    "        n_vals = sorted(multi_results.keys())  # Should be [1, 3, 5]\n",
    "        \n",
    "        with open(filename, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            \n",
    "            # Write header rows with merged format\n",
    "            # First header row\n",
    "            header1 = ['Frequency', '90B Test', 'Linear Estimate', '', '', 'Monte Carlo Estimate', '', '']\n",
    "            writer.writerow(header1)\n",
    "            \n",
    "            # Second header row\n",
    "            header2 = ['', '', 'n=1', 'n=3', 'n=5', 'n=1', 'n=3', 'n=5']\n",
    "            writer.writerow(header2)\n",
    "            \n",
    "            # Extract frequencies from first result list\n",
    "            first_n = list(multi_results.keys())[0]\n",
    "            first_results = multi_results[first_n]\n",
    "            \n",
    "            # For each frequency, create a row\n",
    "            for result in first_results:\n",
    "                freq = result['filename'].split('_')[1].replace('G', 'GHz')\n",
    "                row = [freq, result['hmin_90b']]\n",
    "                \n",
    "                # Add linear estimates for all n values\n",
    "                for n in n_vals:\n",
    "                    n_results = multi_results[n]\n",
    "                    n_result = next((r for r in n_results if r['filename'] == result['filename']), None)\n",
    "                    \n",
    "                    if n_result:\n",
    "                        row.append(n_result['hmin_linear'])\n",
    "                    else:\n",
    "                        row.append('N/A')\n",
    "                \n",
    "                # Add Monte Carlo estimates for all n values\n",
    "                for n in n_vals:\n",
    "                    n_results = multi_results[n]\n",
    "                    n_result = next((r for r in n_results if r['filename'] == result['filename']), None)\n",
    "                    \n",
    "                    if n_result:\n",
    "                        row.append(n_result['hmin_mc'])\n",
    "                    else:\n",
    "                        row.append('N/A')\n",
    "                \n",
    "                writer.writerow(row)\n",
    "        \n",
    "        print(f\"Merged format CSV table saved to {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating merged format CSV table: {e}\", file=sys.stderr)\n",
    "\n",
    "# ---------- Visualization functions ----------\n",
    "def create_visualizations(results: List[Dict]):\n",
    "    \"\"\"Create visualizations for the analysis results\"\"\"\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        import matplotlib\n",
    "        matplotlib.rcParams.update({'font.size': 10})\n",
    "        \n",
    "        # Extract data for plotting\n",
    "        frequencies = []\n",
    "        hmin_90b = []\n",
    "        hmin_linear = []\n",
    "        hmin_mc = []\n",
    "        alphas = []\n",
    "        betas = []\n",
    "        r_vals = []\n",
    "        \n",
    "        for result in results:\n",
    "            if result['error'] is None:\n",
    "                freq = result['filename'].split('_')[1].replace('G', 'GHz')\n",
    "                frequencies.append(freq)\n",
    "                hmin_90b.append(result['hmin_90b'])\n",
    "                hmin_linear.append(result['hmin_linear'])\n",
    "                hmin_mc.append(result['hmin_mc'])\n",
    "                alphas.append(result.get('alpha', 0.0))\n",
    "                betas.append(result.get('beta', 0.0))\n",
    "                r_vals.append(result.get('r', 0.0))\n",
    "        \n",
    "        if not frequencies:\n",
    "            print(\"No valid results for visualization\")\n",
    "            return\n",
    "        \n",
    "        # Create figure with subplots\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        fig.suptitle('Min-Entropy Analysis Results', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # 1. Main comparison line plot\n",
    "        ax1 = axes[0, 0]\n",
    "        ax1.plot(frequencies, hmin_90b, 'o-', linewidth=2, markersize=8, \n",
    "                label='90B Test', color='blue')\n",
    "        ax1.plot(frequencies, hmin_linear, 's-', linewidth=2, markersize=8,\n",
    "                label='Linear Estimate', color='green')\n",
    "        ax1.plot(frequencies, hmin_mc, '^-', linewidth=2, markersize=8,\n",
    "                label='Monte Carlo', color='red')\n",
    "        \n",
    "        ax1.set_xlabel('Frequency')\n",
    "        ax1.set_ylabel('Min-Entropy (bits)')\n",
    "        ax1.set_title('Min-Entropy Comparison')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. Difference from 90B results\n",
    "        ax2 = axes[0, 1]\n",
    "        diff_linear = np.abs(np.array(hmin_linear) - np.array(hmin_90b))\n",
    "        diff_mc = np.abs(np.array(hmin_mc) - np.array(hmin_90b))\n",
    "        \n",
    "        x = np.arange(len(frequencies))\n",
    "        width = 0.35\n",
    "        \n",
    "        bars1 = ax2.bar(x - width/2, diff_linear, width, label='Linear Difference', \n",
    "                       color='green', alpha=0.7)\n",
    "        bars2 = ax2.bar(x + width/2, diff_mc, width, label='Monte Carlo Difference',\n",
    "                       color='red', alpha=0.7)\n",
    "        \n",
    "        ax2.set_xlabel('Frequency')\n",
    "        ax2.set_ylabel('Absolute Difference from 90B (bits)')\n",
    "        ax2.set_title('Estimation Errors')\n",
    "        ax2.set_xticks(x)\n",
    "        ax2.set_xticklabels(frequencies)\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bars in [bars1, bars2]:\n",
    "            for bar in bars:\n",
    "                height = bar.get_height()\n",
    "                ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                        f'{height:.3f}', ha='center', va='bottom', fontsize=8)\n",
    "        \n",
    "        # 3. Parameter values\n",
    "        ax3 = axes[0, 2]\n",
    "        \n",
    "        x = np.arange(len(frequencies))\n",
    "        width = 0.25\n",
    "        \n",
    "        bars1 = ax3.bar(x - width, alphas, width, label='Alpha (r_f)', \n",
    "                       color='blue', alpha=0.7)\n",
    "        bars2 = ax3.bar(x, betas, width, label='Beta', \n",
    "                       color='orange', alpha=0.7)\n",
    "        bars3 = ax3.bar(x + width, np.abs(r_vals), width, label='|r_u|', \n",
    "                       color='purple', alpha=0.7)\n",
    "        \n",
    "        ax3.set_xlabel('Frequency')\n",
    "        ax3.set_ylabel('Parameter Value')\n",
    "        ax3.set_title('Model Parameters by Frequency')\n",
    "        ax3.set_xticks(x)\n",
    "        ax3.set_xticklabels(frequencies)\n",
    "        ax3.legend()\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. Scatter plot: Linear vs Monte Carlo estimates\n",
    "        ax4 = axes[1, 0]\n",
    "        \n",
    "        # Perfect correlation line\n",
    "        min_val = min(min(hmin_linear), min(hmin_mc))\n",
    "        max_val = max(max(hmin_linear), max(hmin_mc))\n",
    "        ax4.plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.5, label='y=x')\n",
    "        \n",
    "        # Scatter points with frequency labels\n",
    "        scatter = ax4.scatter(hmin_linear, hmin_mc, c=range(len(frequencies)), \n",
    "                             cmap='viridis', s=100, alpha=0.7)\n",
    "        \n",
    "        # Add frequency labels to points\n",
    "        for i, freq in enumerate(frequencies):\n",
    "            ax4.annotate(freq, (hmin_linear[i], hmin_mc[i]), \n",
    "                        xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "        \n",
    "        ax4.set_xlabel('Linear Estimate (bits)')\n",
    "        ax4.set_ylabel('Monte Carlo Estimate (bits)')\n",
    "        ax4.set_title('Linear vs Monte Carlo Estimates')\n",
    "        ax4.legend()\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 5. Relative error comparison\n",
    "        ax5 = axes[1, 1]\n",
    "        \n",
    "        # Calculate relative errors\n",
    "        rel_error_linear = diff_linear / np.array(hmin_90b) * 100\n",
    "        rel_error_mc = diff_mc / np.array(hmin_90b) * 100\n",
    "        \n",
    "        x = np.arange(len(frequencies))\n",
    "        bar_width = 0.35\n",
    "        \n",
    "        bars_linear = ax5.bar(x - bar_width/2, rel_error_linear, bar_width, \n",
    "                             label='Linear Error (%)', color='green', alpha=0.7)\n",
    "        bars_mc = ax5.bar(x + bar_width/2, rel_error_mc, bar_width, \n",
    "                         label='Monte Carlo Error (%)', color='red', alpha=0.7)\n",
    "        \n",
    "        ax5.set_xlabel('Frequency')\n",
    "        ax5.set_ylabel('Relative Error (%)')\n",
    "        ax5.set_title('Relative Errors Compared to 90B')\n",
    "        ax5.set_xticks(x)\n",
    "        ax5.set_xticklabels(frequencies)\n",
    "        ax5.legend()\n",
    "        ax5.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bars in [bars_linear, bars_mc]:\n",
    "            for bar in bars:\n",
    "                height = bar.get_height()\n",
    "                ax5.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                        f'{height:.1f}%', ha='center', va='bottom', fontsize=8)\n",
    "        \n",
    "        # 6. Correlation heatmap\n",
    "        ax6 = axes[1, 2]\n",
    "        \n",
    "        # Create correlation matrix\n",
    "        data_matrix = np.array([hmin_90b, hmin_linear, hmin_mc, alphas, betas, np.abs(r_vals)])\n",
    "        corr_matrix = np.corrcoef(data_matrix)\n",
    "        \n",
    "        # Labels for the matrix\n",
    "        labels = ['90B', 'Linear', 'MC', 'Alpha', 'Beta', '|r_u|']\n",
    "        \n",
    "        # Create heatmap\n",
    "        im = ax6.imshow(corr_matrix, cmap='RdYlBu', vmin=-1, vmax=1)\n",
    "        \n",
    "        # Add text annotations\n",
    "        for i in range(len(labels)):\n",
    "            for j in range(len(labels)):\n",
    "                text = ax6.text(j, i, f'{corr_matrix[i, j]:.2f}',\n",
    "                              ha='center', va='center', color='black', fontsize=8)\n",
    "        \n",
    "        ax6.set_xticks(range(len(labels)))\n",
    "        ax6.set_yticks(range(len(labels)))\n",
    "        ax6.set_xticklabels(labels, rotation=45)\n",
    "        ax6.set_yticklabels(labels)\n",
    "        ax6.set_title('Correlation Matrix')\n",
    "        \n",
    "        # Add colorbar\n",
    "        plt.colorbar(im, ax=ax6, fraction=0.046, pad=0.04)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the figure\n",
    "        plt.savefig('entropy_analysis_visualizations.png', dpi=300, bbox_inches='tight')\n",
    "        print(\"Visualizations saved as 'entropy_analysis_visualizations.png'\")\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"Matplotlib not available. Skipping visualizations.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating visualizations: {e}\")\n",
    "\n",
    "# ---------- Main program ----------\n",
    "def main():\n",
    "    \"\"\"Main function: analyze all files and generate comparison tables and visualizations\"\"\"\n",
    "    # File list and corresponding 90B test results\n",
    "    file_data = [\n",
    "        (\"1.3V_1G.bin\", 0.613673),\n",
    "        (\"1.3V_2G.bin\", 0.567689),\n",
    "        (\"1.3V_3G.bin\", 0.519764),\n",
    "        (\"1.3V_4G.bin\", 0.513656),\n",
    "        (\"1.3V_5G.bin\", 0.328293)\n",
    "    ]\n",
    "    \n",
    "    # Load parameters from CSV file\n",
    "    parameters = load_parameters_from_csv(\"parameter_table.csv\")\n",
    "    \n",
    "    if not parameters:\n",
    "        print(\"ERROR: Could not load parameters from CSV file\", file=sys.stderr)\n",
    "        return\n",
    "    \n",
    "    # Analysis history length - only analyze n=1, 3, 5\n",
    "    n_history_list = [1, 3, 5]\n",
    "    \n",
    "    # Monte Carlo samples\n",
    "    mc_samples = 10000000\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"MIN-ENTROPY ANALYSIS WITH DYNAMIC PARAMETERS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Analysis started at: {datetime.datetime.now()}\")\n",
    "    print(f\"Analyzing n_history values: {n_history_list}\")\n",
    "    print(f\"b is automatically determined from r_u sign\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Store results for each n_history\n",
    "    multi_results = {}\n",
    "    \n",
    "    # Analyze for each n_history value\n",
    "    for n_history in n_history_list:\n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"ANALYZING WITH n = {n_history}\")\n",
    "        print(f\"{'='*40}\")\n",
    "        \n",
    "        # Store results for this n_history\n",
    "        all_results = []\n",
    "        \n",
    "        # Analyze each file with its corresponding parameters\n",
    "        for filename, hmin_90b in file_data:\n",
    "            # Extract frequency from filename to match with parameter table\n",
    "            freq_from_file = filename.split('_')[1].replace('G', 'GHz')\n",
    "            \n",
    "            print(f\"\\nAnalyzing file: {filename}\")\n",
    "            print(f\"90B test result: {hmin_90b:.6f}\")\n",
    "            print(f\"Extracted frequency: {freq_from_file}\")\n",
    "            \n",
    "            # Get parameters for this frequency\n",
    "            if freq_from_file in parameters:\n",
    "                params = parameters[freq_from_file]\n",
    "                print(f\"Using parameters for {freq_from_file}:\")\n",
    "                print(f\"  r_u (used as r): {params['r_u']:.6f}\")\n",
    "                print(f\"  r_f (alpha): {params['r_f']:.6f}\")\n",
    "                print(f\"  beta: {params['beta']:.6f}\")\n",
    "                print(f\"  p_hat: {params['p_hat']:.6f} (for reference only)\")\n",
    "                \n",
    "                # Determine b based on r_u\n",
    "                b = determine_b_from_r_u(params['r_u'])\n",
    "                print(f\"  Determined b: {b} (from r_u sign)\")\n",
    "                \n",
    "                # Analyze with parameters - USING r_u AS r\n",
    "                result = analyze_bin_file_with_params(\n",
    "                    filename=filename,\n",
    "                    n_history=n_history,\n",
    "                    alpha=params['r_f'],  # Use r_f as alpha\n",
    "                    beta=params['beta'],   # Use beta from CSV\n",
    "                    r_u=params['r_u'],     # Use r_u as the r parameter\n",
    "                    mc_samples=mc_samples\n",
    "                )\n",
    "                \n",
    "                # Add 90B result and p_hat for reference\n",
    "                result['hmin_90b'] = hmin_90b\n",
    "                result['p_hat'] = params['p_hat']  # Store for reference\n",
    "                result['param_source'] = freq_from_file\n",
    "                \n",
    "                all_results.append(result)\n",
    "                \n",
    "                print(f\"  Linear estimate: p={result['p_linear']:.6f}, H_min={result['hmin_linear']:.6f}\")\n",
    "                print(f\"  Monte Carlo: p={result['p_mc']:.6f}, H_min={result['hmin_mc']:.6f}\")\n",
    "            else:\n",
    "                print(f\"WARNING: No parameters found for frequency {freq_from_file}\")\n",
    "                continue\n",
    "        \n",
    "        # Store results for this n_history\n",
    "        multi_results[n_history] = all_results\n",
    "        \n",
    "        # Print summary table for this n_history\n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"RESULTS SUMMARY FOR n = {n_history}\")\n",
    "        print(f\"{'='*40}\")\n",
    "        print(f\"{'Frequency':<12} {'90B Test':<12} {'Linear':<12} {'Monte Carlo':<12} {'Diff (Lin)':<12} {'Diff (MC)':<12}\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        total_diff_linear = 0\n",
    "        total_diff_mc = 0\n",
    "        valid_results = 0\n",
    "        \n",
    "        for result in all_results:\n",
    "            if result['error'] is None:\n",
    "                freq = result['filename'].split('_')[1].replace('G', 'GHz')\n",
    "                diff_linear = abs(result['hmin_linear'] - result['hmin_90b'])\n",
    "                diff_mc = abs(result['hmin_mc'] - result['hmin_90b'])\n",
    "                \n",
    "                total_diff_linear += diff_linear\n",
    "                total_diff_mc += diff_mc\n",
    "                valid_results += 1\n",
    "                \n",
    "                print(f\"{freq:<12} {result['hmin_90b']:<12.6f} {result['hmin_linear']:<12.6f} {result['hmin_mc']:<12.6f} {diff_linear:<12.6f} {diff_mc:<12.6f}\")\n",
    "        \n",
    "        if valid_results > 0:\n",
    "            avg_diff_linear = total_diff_linear / valid_results\n",
    "            avg_diff_mc = total_diff_mc / valid_results\n",
    "            \n",
    "            print(\"-\" * 80)\n",
    "            print(f\"{'Average Diff':<12} {'':<12} {'':<12} {'':<12} {avg_diff_linear:<12.6f} {avg_diff_mc:<12.6f}\")\n",
    "        \n",
    "        # Save results to CSV files for this n_history\n",
    "        save_results_to_csv(all_results, f\"entropy_results_n{n_history}_summary.csv\", n_history=n_history, include_params=False)\n",
    "        save_results_to_csv(all_results, f\"entropy_results_n{n_history}_detailed.csv\", n_history=n_history, include_params=True)\n",
    "        \n",
    "        # Generate TeX tables for this n_history\n",
    "        generate_tex_table(all_results, f\"entropy_results_table_n{n_history}.tex\", n_history=n_history)\n",
    "    \n",
    "    # Generate tables with merged format\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"GENERATING TABLES WITH MERGED HEADER FORMAT\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Generate CSV table with merged format\n",
    "    generate_merged_format_csv_table(multi_results, \"entropy_results_merged_format.csv\")\n",
    "    \n",
    "    # Generate Excel table with merged format\n",
    "    generate_merged_format_excel_table(multi_results, \"entropy_results_merged_format.xlsx\")\n",
    "    \n",
    "    # Generate TeX table with merged format\n",
    "    generate_merged_format_tex_table(multi_results, \"entropy_results_merged_format.tex\")\n",
    "    \n",
    "    # Create visualizations for the first n_history (n=1)\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"CREATING VISUALIZATIONS FOR n=1\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    if 1 in multi_results:\n",
    "        create_visualizations(multi_results[1])\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ANALYSIS COMPLETE\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(\"Generated files:\")\n",
    "    \n",
    "    # List files for each n_history\n",
    "    for n_history in n_history_list:\n",
    "        print(f\"  For n={n_history}:\")\n",
    "        print(f\"    1. entropy_results_n{n_history}_summary.csv\")\n",
    "        print(f\"    2. entropy_results_n{n_history}_detailed.csv\")\n",
    "        print(f\"    3. entropy_results_table_n{n_history}.tex\")\n",
    "    \n",
    "    print(f\"\\n  Multi-n tables with merged header format:\")\n",
    "    print(f\"    1. entropy_results_merged_format.csv\")\n",
    "    print(f\"    2. entropy_results_merged_format.xlsx (Excel format with merged cells)\")\n",
    "    print(f\"    3. entropy_results_merged_format.tex (TeX format with merged cells)\")\n",
    "    print(f\"\\n  Visualizations (for n=1):\")\n",
    "    print(f\"    1. entropy_analysis_visualizations.png (if matplotlib available)\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
